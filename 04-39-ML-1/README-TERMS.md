## Некоторые термины и определения модуля ML-1 (Теория машинного обучения) ##

**Искусственный интеллект (Artificial Intelligence)**&nbsp;&mdash; способность
компьютерной системы имитировать когнитивные функции человека, такие как
обучение и решение задач. AI позволяет компьютеру моделировать рассуждения людей
для получения новых сведений и принятия решений.

**Слабый ИИ (Weak AI)** способен решать только одну задачу. В качестве примера
слабого ИИ можно назвать `Deep Blue`. Но `Deep Blue` не умеет делать ничего
другого и никогда этому не научится. Слабый ИИ используют в медицине, логистике,
банковском деле, бизнесе.

**Сильный ИИ (Strong AI)** пока остаётся мечтой. Это интеллект, который решает
множество задач и умеет обучаться для решения других. Сильный ИИ осознаёт себя и
своё существование.

**Подразделы искусственного интеллекта**

- Робототехника (Robotics)
- Компьютерное зрение (Computer Vision)
- Обработка естественного языка (Natural Language Processing)
- Машинное обучение (Machine Learning).

----

**Машинное обучение (Machine Learning)**&nbsp;&mdash; один из разделов науки об
искусственном интеллекте. Машинное обучение заключается в построении моделей с
помощью поиска закономерностей в данных и использовании их для того, чтобы
спрогнозировать характеристики новых данных.

### Составные части ML ###

1. **Набор данных (dataset)**&nbsp;&mdash; множество примеров (выборка), на
котором происходит обучение модели. Это могут быть табличные данные, текст,
аудио, изображения (видео).
2. **Признаки (features)**&nbsp;&mdash; свойства, характеристики, которыми
описываются объекты. Признак, который надо предсказать, называется
**целевым признаком (target feature)**. Иногда признаки, на основе которых надо
предсказать целевой, могут называться **факторами (factors)**.
3. **Модель машинного обучения (ML-model)**&nbsp;&mdash; некоторый математически
формализованный метод (алгоритм) описания зависимости в данных. Как правило,
модель имеет настраиваемые (регулируемые) параметры. В простом понимании
модель&nbsp;&mdash; математическая формула, которая связывает факторы с целевым
признаком. В более обширном понимании модель может выражаться не
формулой&nbsp;&mdash; это может быть математически описанная последовательность
действий (алгоритм). Управляя своими параметрами, модель подстраивается под
зависимости в данных, чтобы описать эту зависимость и свести ошибку в
предсказаниях к минимуму. Такой процесс называется
**обучением модели (model learning)**.

----

За управление параметрами отвечает некоторая **функция ошибки**, или, как её ещё
называют, **функция потерь (loss function)**. Это некоторая математическая
функция, которая показывает различие между фактическими ответами и
предсказаниями модели.

Самые простые примеры функции ошибки&nbsp;&mdash; **MAE (Mean Absolute Error)**
и **MSE (Mean Squared Error)** (средний квадрат разницы между ответами).
Формально они записываются следующим образом:
$$MAE=\frac{1}{n}\displaystyle\sum_{i=1}^n|y_i-\widehat{y_i}|$$
$$MSE=\frac{1}{n}\displaystyle\sum_{i=1}^n(y_i-\widehat{y_i})^2,$$
где $y$&nbsp;&mdash; истинные ответы, $\widehat{y}$&nbsp;&mdash; предсказания,
$n$&nbsp;&mdash; количество примеров.

----

**Метрика (metric)**&nbsp;&mdash; численное выражение качества модели (или её
ошибки). Иногда метрика может совпадать с функцией потерь, но чаще всего они
различны. Метрика, как правило, должна быть интерпретируемой и понятной&nbsp;&mdash;
в этом её главное отличие от функции потерь.

----

**Глубокое обучение (Deep Learning)**&nbsp;&mdash; подраздел машинного обучения.
Глубокое обучение основано на изучении и применении в качестве инструмента для
решения задач **искусственных нейронных сетей**. Данные алгоритмы основаны на
имитации работы человеческого мозга.

----

**Карта машинного обучения**

![Карта машинного обучения](ml-map.png)

1. Supervised Learning&nbsp;&mdash; обучение с учителем (у машины есть некий
учитель, который сообщает ей, как поступать правильно, рассказывает, что на этой
картинке изображена кошка, а на этой&nbsp;&mdash; собака, а машина учится на
конкретных примерах и правильных ответах к ним). Данные, в которых содержится
информация о целевом признаке, называются **размеченными**.
2. Unsupervised Learning&nbsp;&mdash; обучение без учителя
3. Reinforcement Learning&nbsp;&mdash; обучение с подкреплением

----

### Обучение с учителем ###

**Регрессия (regression)**&nbsp;&mdash; задача предсказания вещественного числа
на основе признаков в наборе данных. То есть задача сводится к предсказанию
целевого признака, который является числовым.

**Прогнозирование (forecasting)**&nbsp;&mdash; это задача регрессии, попытка
предсказать будущее поведение временного ряда, то есть целевая переменная
является числовой и зависит от времени. Причём каждому моменту времени
соответствует одно конкретное значение. Можно сказать, что
прогнозирование&nbsp;&mdash; это частный случай регрессии.

Методы регрессии с небольшими изменениями подходят и для решения задачи
прогнозирования. Однако, как правило, большей эффективностью обладают модели,
которые разработаны специально для **прогнозирования временных рядов**,
например:

- ARIMA
- SARIMA (модификация ARIMA)
- ARCH (модель для финансовых временных рядов)

----

**Классификация (classification)**&nbsp;&mdash; задача предсказания класса
объекта на основе признаков в наборе данных. То есть задача сводится к
предсказанию целевого признака, который является категориальным.

Чаще всего бывает **бинарная классификация**: целевой признак имеет две
возможные категории (&laquo;да&raquo;&nbsp;&mdash; 1 или
&laquo;нет&raquo;&nbsp;&mdash; 0).

Когда классов, которые надо предсказать, более двух, это
**мультиклассовая (многоклассовая) классификация**. Любую мультиклассовую задачу
классификации можно свести к бинарной классификации методом
**&laquo;один против всех&raquo;**. Суть метода: какую-то из категорий
обозначают за 1, а оставшиеся за 0 и решается задача бинарной классификации.
Затем повторяется процедура для остальных категорий.

Для решения задачи **классификации** может использоваться множество моделей:

- Логистическая регрессия (Logistic Regression)
- Метод опорных векторов (SVM)
- Деревья решений (Decision Tree)
- Наивный байесовский классификатор (Naive Bayes)
- Метод ближайших соседей (kNN)

----

### Обучение без учителя ###

**Кластеризация (clustering)**&nbsp;&mdash; задача разделения данных на группы
на основе признаков в данных.

**Типичные методы кластеризации при известном заранее количестве кластеров**:

- метод k-средних (k-means)
- EM-алгоритм
- агломеративная кластеризация.

**Понижение размерности (dimensionality reduction)**&nbsp;&mdash; задача
уменьшения количество признаков, характеризующих объект. Обычно уменьшается
количество признаков до 2-3 для того, чтобы получить возможность визуализировать
данные.

**Основные алгоритмы понижения размерности**:

- Метод главных компонент (PCA)
- Сингулярное разложение (SVD)
- Латентное размещение Дирихле (LDA)
- Латентный семантический анализ (LSA)
- t-SNE

**Ассоциация (association)**&nbsp;&mdash; задача нахождения правил и законов, по
которым существует последовательность действий.

**Основные ассоциативные модели**:

- Apriori
- Eclat
- FP Growth

----

### Обучение с подкреплением ###

**Обучение с подкреплением** кардинально отличается от обучения с учителем и без
него, поэтому его выделяют в отдельный вид обучения. Это не задачи, связанные с
анализом данных и предсказанием, а задачи взаимодействия со средой и
&laquo;выживания&raquo; в ней.

В **Q-learning** рассматриваются все состояния, в которых может находиться
агент, и все возможные переходы из одного состояния в другое, которые
определяются действиями. Вводится некоторая Q-функция, которая оценивает, какую
награду получит агент при совершении действия из своего состояния. Уравнение
Беллмана помогает определить следующее оптимальное действие, такое, что значение
Q-функции для определённой пары состояние-действие будет максимальной. Цель
Q-learning&nbsp;&mdash; приближённо найти (аппроксимировать) Q-функцию, которая
ответит на вопрос, как нужно правильно играть, чтобы получить максимум награды.

----

### Методологии разработки ###

1. Водопадная методология (**Waterfall, &laquo;Водопад&raquo;**)&nbsp;&mdash;
модель процесса разработки ПО в виде потока последовательных фаз.
2. Гибкая методология (**Agile**)&nbsp;&mdash; модель процесса разработки ПО с
гибким возвратом к любому этапу: если тест спроектированной модели не дал
нужного результата, то разработчик может начать с самого начала.
3. **CRISP-DM (Cross-Industry Standard Process for Data Mining)**&nbsp;&mdash;
наиболее распространённая и проверенная методология по работе с проектами,
завязанными на данных. Модель жизненного цикла исследования данных в методологии
состоит из шести фаз.
    - Анализ требований
    - Исследование данных
    - Подготовка данных
    - Построение модели
    - Оценка модели
    - Внедрение

**Особенности методологии CRISP-DM**:

- Методология CRISP-DM разработана специалистами по работе с данными и учитывает
особенности DS-проектов.
- Иногда говорят, что CRISP-DM является обобщением методологии Agile на DS. В
частности, методология является итеративной (проект состоит из спринтов).
- Последовательность этапов строго не определена, некоторые этапы можно менять
местами. Возможна параллельность этапов (например, подготовка данных и их
исследования могут вестись одновременно). Предусмотрены возвраты на предыдущие
этапы.
- Фиксирование ключевых моментов проекта: графиков, найденных закономерностей,
результатов проверки гипотез, используемых моделей и полученных метрик на каждой
итерации цикла разработки.

----
